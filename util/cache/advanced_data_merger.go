package cache

import (
	"fmt"
	"sync"
	"time"

	"pansou/model"
)

// AdvancedDataMerger é«˜çº§æ•°æ®åˆå¹¶å™¨
type AdvancedDataMerger struct {
	// åˆå¹¶ç­–ç•¥
	mergeStrategies  map[string]MergeStrategy
	
	// åˆå¹¶è§„åˆ™
	mergeRules       []*MergeRule
	
	// ç»Ÿè®¡ä¿¡æ¯
	totalMerges      int64
	successfulMerges int64
	failedMerges     int64
	
	// ç¼“å­˜å»é‡
	deduplicationMap map[string]*CacheOperation
	dedupMutex       sync.RWMutex
	
	// æ€§èƒ½ç›‘æ§
	mergeMetrics     *MergeMetrics
	
	mutex            sync.RWMutex
}

// MergeStrategy åˆå¹¶ç­–ç•¥æ¥å£
type MergeStrategy interface {
	CanMerge(existing *CacheOperation, new *CacheOperation) bool
	Merge(existing *CacheOperation, new *CacheOperation) (*CacheOperation, error)
	GetPriority() int
}

// MergeRule åˆå¹¶è§„åˆ™
type MergeRule struct {
	Name         string
	Description  string
	Condition    func(*CacheOperation, *CacheOperation) bool
	MergeFunc    func(*CacheOperation, *CacheOperation) (*CacheOperation, error)
	Priority     int
	Enabled      bool
}

// MergeMetrics åˆå¹¶æŒ‡æ ‡
type MergeMetrics struct {
	// æ—¶é—´ç»Ÿè®¡
	AverageMergeTime    time.Duration
	MaxMergeTime        time.Duration
	TotalMergeTime      time.Duration
	
	// æ•°æ®ç»Ÿè®¡
	DataSizeBefore      int64
	DataSizeAfter       int64
	CompressionRatio    float64
	
	// ç±»å‹ç»Ÿè®¡
	MergesByType        map[string]int64
	MergesByPlugin      map[string]int64
	MergesByKeyword     map[string]int64
	
	// æ•ˆç‡ç»Ÿè®¡
	DuplicatesRemoved   int64
	ResultsConsolidated int64
	StorageSaved        int64
}

// NewAdvancedDataMerger åˆ›å»ºé«˜çº§æ•°æ®åˆå¹¶å™¨
func NewAdvancedDataMerger() *AdvancedDataMerger {
	merger := &AdvancedDataMerger{
		mergeStrategies:  make(map[string]MergeStrategy),
		deduplicationMap: make(map[string]*CacheOperation),
		mergeMetrics:     &MergeMetrics{
			MergesByType:    make(map[string]int64),
			MergesByPlugin:  make(map[string]int64),
			MergesByKeyword: make(map[string]int64),
		},
	}
	
	// åˆå§‹åŒ–åˆå¹¶ç­–ç•¥
	merger.initializeMergeStrategies()
	
	// åˆå§‹åŒ–åˆå¹¶è§„åˆ™
	merger.initializeMergeRules()
	
	return merger
}

// initializeMergeStrategies åˆå§‹åŒ–åˆå¹¶ç­–ç•¥
func (m *AdvancedDataMerger) initializeMergeStrategies() {
	// æ³¨å†ŒåŒé”®åˆå¹¶ç­–ç•¥
	m.mergeStrategies["same_key"] = &SameKeyMergeStrategy{}
	
	// æ³¨å†ŒåŒæ’ä»¶åŒå…³é”®è¯ç­–ç•¥
	m.mergeStrategies["same_plugin_keyword"] = &SamePluginKeywordMergeStrategy{}
	
	// æ³¨å†Œç»“æœå»é‡ç­–ç•¥
	m.mergeStrategies["deduplication"] = &DeduplicationMergeStrategy{}
	
	// æ³¨å†Œå†…å®¹ç›¸ä¼¼æ€§ç­–ç•¥
	m.mergeStrategies["content_similarity"] = &ContentSimilarityMergeStrategy{}
}

// initializeMergeRules åˆå§‹åŒ–åˆå¹¶è§„åˆ™
func (m *AdvancedDataMerger) initializeMergeRules() {
	m.mergeRules = []*MergeRule{
		{
			Name:        "å®Œå…¨ç›¸åŒé”®åˆå¹¶",
			Description: "åˆå¹¶å…·æœ‰å®Œå…¨ç›¸åŒç¼“å­˜é”®çš„æ“ä½œ",
			Condition: func(existing, new *CacheOperation) bool {
				return existing.Key == new.Key
			},
			MergeFunc: m.mergeSameKey,
			Priority:  1,
			Enabled:   true,
		},
		{
			Name:        "åŒæ’ä»¶åŒå…³é”®è¯åˆå¹¶",
			Description: "åˆå¹¶åŒä¸€æ’ä»¶å¯¹åŒä¸€å…³é”®è¯çš„æœç´¢ç»“æœ",
			Condition: func(existing, new *CacheOperation) bool {
				return existing.PluginName == new.PluginName && 
				       existing.Keyword == new.Keyword &&
				       existing.Key != new.Key
			},
			MergeFunc: m.mergeSamePluginKeyword,
			Priority:  2,
			Enabled:   true,
		},
		{
			Name:        "æ—¶é—´çª—å£å†…åˆå¹¶",
			Description: "åˆå¹¶æ—¶é—´çª—å£å†…çš„ç›¸ä¼¼æ“ä½œ",
			Condition: func(existing, new *CacheOperation) bool {
				timeDiff := new.Timestamp.Sub(existing.Timestamp)
				return timeDiff >= 0 && timeDiff <= 5*time.Minute &&
				       existing.PluginName == new.PluginName
			},
			MergeFunc: m.mergeTimeWindow,
			Priority:  3,
			Enabled:   true,
		},
		{
			Name:        "ç»“æœå»é‡åˆå¹¶",
			Description: "å»é™¤é‡å¤çš„æœç´¢ç»“æœ",
			Condition: func(existing, new *CacheOperation) bool {
				return m.hasOverlapResults(existing, new)
			},
			MergeFunc: m.mergeDeduplication,
			Priority:  4,
			Enabled:   true,
		},
	}
}

// TryMergeOperation å°è¯•åˆå¹¶æ“ä½œ
func (m *AdvancedDataMerger) TryMergeOperation(buffer *GlobalBuffer, newOp *CacheOperation) bool {
	startTime := time.Now()
	defer func() {
		mergeTime := time.Since(startTime)
		m.updateMergeMetrics(mergeTime)
	}()
	
	m.totalMerges++
	
	// ğŸ” åœ¨ç¼“å†²åŒºä¸­å¯»æ‰¾å¯åˆå¹¶çš„æ“ä½œ
	merged := false
	
	for i, existingOp := range buffer.Operations {
		if m.canMergeOperations(existingOp, newOp) {
			// ğŸš€ æ‰§è¡Œåˆå¹¶
			mergedOp, err := m.performMerge(existingOp, newOp)
			if err != nil {
				m.failedMerges++
				continue
			}
			
			// æ›¿æ¢åŸæ“ä½œ
			buffer.Operations[i] = mergedOp
			
			// æ›´æ–°ç»Ÿè®¡
			m.successfulMerges++
			m.updateMergeStatistics(existingOp, newOp, mergedOp)
			
			merged = true
			break
		}
	}
	
	return merged
}

// canMergeOperations æ£€æŸ¥æ˜¯å¦å¯ä»¥åˆå¹¶æ“ä½œ
func (m *AdvancedDataMerger) canMergeOperations(existing, new *CacheOperation) bool {
	// æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥åˆå¹¶è§„åˆ™
	for _, rule := range m.mergeRules {
		if rule.Enabled && rule.Condition(existing, new) {
			return true
		}
	}
	
	return false
}

// performMerge æ‰§è¡Œåˆå¹¶
func (m *AdvancedDataMerger) performMerge(existing, new *CacheOperation) (*CacheOperation, error) {
	// æ‰¾åˆ°æœ€é«˜ä¼˜å…ˆçº§çš„é€‚ç”¨è§„åˆ™
	var bestRule *MergeRule
	for _, rule := range m.mergeRules {
		if rule.Enabled && rule.Condition(existing, new) {
			if bestRule == nil || rule.Priority < bestRule.Priority {
				bestRule = rule
			}
		}
	}
	
	if bestRule == nil {
		return nil, fmt.Errorf("æœªæ‰¾åˆ°é€‚ç”¨çš„åˆå¹¶è§„åˆ™")
	}
	
	// æ‰§è¡Œåˆå¹¶
	return bestRule.MergeFunc(existing, new)
}

// mergeSameKey åˆå¹¶ç›¸åŒé”®çš„æ“ä½œ
func (m *AdvancedDataMerger) mergeSameKey(existing, new *CacheOperation) (*CacheOperation, error) {
	// åˆå¹¶æœç´¢ç»“æœ
	mergedResults := m.mergeSearchResults(existing.Data, new.Data)
	
	merged := &CacheOperation{
		Key:        existing.Key,
		Data:       mergedResults,
		TTL:        m.chooseLongerTTL(existing.TTL, new.TTL),
		PluginName: existing.PluginName, // ä¿æŒåŸæ’ä»¶å
		Keyword:    existing.Keyword,    // ä¿æŒåŸå…³é”®è¯
		Timestamp:  new.Timestamp,       // ä½¿ç”¨æœ€æ–°æ—¶é—´æˆ³
		Priority:   m.chooseBetterPriority(existing.Priority, new.Priority),
		DataSize:   existing.DataSize + new.DataSize, // ç´¯è®¡æ•°æ®å¤§å°
		IsFinal:    existing.IsFinal || new.IsFinal,  // ä»»ä¸€ä¸ºæœ€ç»ˆç»“æœåˆ™ä¸ºæœ€ç»ˆç»“æœ
	}
	
	return merged, nil
}

// mergeSamePluginKeyword åˆå¹¶åŒæ’ä»¶åŒå…³é”®è¯æ“ä½œ
func (m *AdvancedDataMerger) mergeSamePluginKeyword(existing, new *CacheOperation) (*CacheOperation, error) {
	// ç”Ÿæˆæ–°çš„åˆå¹¶é”®
	mergedKey := fmt.Sprintf("merged_%s_%s_%d", 
		existing.PluginName, existing.Keyword, time.Now().Unix())
	
	// åˆå¹¶æœç´¢ç»“æœ
	mergedResults := m.mergeSearchResults(existing.Data, new.Data)
	
	merged := &CacheOperation{
		Key:        mergedKey,
		Data:       mergedResults,
		TTL:        m.chooseLongerTTL(existing.TTL, new.TTL),
		PluginName: existing.PluginName,
		Keyword:    existing.Keyword,
		Timestamp:  new.Timestamp,
		Priority:   m.chooseBetterPriority(existing.Priority, new.Priority),
		DataSize:   len(mergedResults) * 500, // é‡æ–°ä¼°ç®—æ•°æ®å¤§å°
		IsFinal:    existing.IsFinal || new.IsFinal,
	}
	
	return merged, nil
}

// mergeTimeWindow åˆå¹¶æ—¶é—´çª—å£å†…çš„æ“ä½œ
func (m *AdvancedDataMerger) mergeTimeWindow(existing, new *CacheOperation) (*CacheOperation, error) {
	// æ—¶é—´çª—å£åˆå¹¶ç­–ç•¥ï¼šä¿ç•™æœ€æ–°çš„å…ƒä¿¡æ¯ï¼Œåˆå¹¶æ•°æ®
	mergedResults := m.mergeSearchResults(existing.Data, new.Data)
	
	merged := &CacheOperation{
		Key:        new.Key, // ä½¿ç”¨æ–°çš„é”®
		Data:       mergedResults,
		TTL:        new.TTL, // ä½¿ç”¨æ–°çš„TTL
		PluginName: new.PluginName,
		Keyword:    new.Keyword,
		Timestamp:  new.Timestamp,
		Priority:   new.Priority,
		DataSize:   len(mergedResults) * 500,
		IsFinal:    new.IsFinal,
	}
	
	return merged, nil
}

// mergeDeduplication å»é‡åˆå¹¶
func (m *AdvancedDataMerger) mergeDeduplication(existing, new *CacheOperation) (*CacheOperation, error) {
	// æ‰§è¡Œæ·±åº¦å»é‡
	deduplicatedResults := m.deduplicateSearchResults(existing.Data, new.Data)
	
	merged := &CacheOperation{
		Key:        existing.Key,
		Data:       deduplicatedResults,
		TTL:        m.chooseLongerTTL(existing.TTL, new.TTL),
		PluginName: existing.PluginName,
		Keyword:    existing.Keyword,
		Timestamp:  new.Timestamp,
		Priority:   m.chooseBetterPriority(existing.Priority, new.Priority),
		DataSize:   len(deduplicatedResults) * 500,
		IsFinal:    existing.IsFinal || new.IsFinal,
	}
	
	return merged, nil
}

// mergeSearchResults åˆå¹¶æœç´¢ç»“æœ
func (m *AdvancedDataMerger) mergeSearchResults(existing, new []model.SearchResult) []model.SearchResult {
	// ä½¿ç”¨mapå»é‡
	resultMap := make(map[string]model.SearchResult)
	
	// æ·»åŠ ç°æœ‰ç»“æœ
	for _, result := range existing {
		key := m.generateResultKey(result)
		resultMap[key] = result
	}
	
	// æ·»åŠ æ–°ç»“æœï¼Œè‡ªåŠ¨å»é‡
	for _, result := range new {
		key := m.generateResultKey(result)
		if existingResult, exists := resultMap[key]; exists {
			// åˆå¹¶ç›¸åŒç»“æœçš„ä¿¡æ¯
			mergedResult := m.mergeIndividualResults(existingResult, result)
			resultMap[key] = mergedResult
		} else {
			resultMap[key] = result
		}
	}
	
	// è½¬æ¢å›åˆ‡ç‰‡
	merged := make([]model.SearchResult, 0, len(resultMap))
	for _, result := range resultMap {
		merged = append(merged, result)
	}
	
	return merged
}

// deduplicateSearchResults æ·±åº¦å»é‡æœç´¢ç»“æœ
func (m *AdvancedDataMerger) deduplicateSearchResults(existing, new []model.SearchResult) []model.SearchResult {
	// æ›´ä¸¥æ ¼çš„å»é‡é€»è¾‘
	resultMap := make(map[string]model.SearchResult)
	duplicateCount := 0
	
	// å¤„ç†ç°æœ‰ç»“æœ
	for _, result := range existing {
		key := m.generateResultKey(result)
		resultMap[key] = result
	}
	
	// å¤„ç†æ–°ç»“æœ
	for _, result := range new {
		key := m.generateResultKey(result)
		if _, exists := resultMap[key]; !exists {
			resultMap[key] = result
		} else {
			duplicateCount++
		}
	}
	
	// æ›´æ–°å»é‡ç»Ÿè®¡
	m.mergeMetrics.DuplicatesRemoved += int64(duplicateCount)
	
	// è½¬æ¢å›åˆ‡ç‰‡
	deduplicated := make([]model.SearchResult, 0, len(resultMap))
	for _, result := range resultMap {
		deduplicated = append(deduplicated, result)
	}
	
	return deduplicated
}

// generateResultKey ç”Ÿæˆç»“æœé”®ç”¨äºå»é‡
func (m *AdvancedDataMerger) generateResultKey(result model.SearchResult) string {
	// ä½¿ç”¨æ ‡é¢˜å’Œä¸»è¦é“¾æ¥ç”Ÿæˆå”¯ä¸€é”®
	key := result.Title
	if len(result.Links) > 0 {
		key += "_" + result.Links[0].URL
	}
	return key
}

// mergeIndividualResults åˆå¹¶å•ä¸ªç»“æœ
func (m *AdvancedDataMerger) mergeIndividualResults(existing, new model.SearchResult) model.SearchResult {
	merged := existing
	
	// é€‰æ‹©æ›´å®Œæ•´çš„å†…å®¹
	if len(new.Content) > len(existing.Content) {
		merged.Content = new.Content
	}
	
	// åˆå¹¶é“¾æ¥
	linkMap := make(map[string]model.Link)
	for _, link := range existing.Links {
		linkMap[link.URL] = link
	}
	for _, link := range new.Links {
		linkMap[link.URL] = link
	}
	
	links := make([]model.Link, 0, len(linkMap))
	for _, link := range linkMap {
		links = append(links, link)
	}
	merged.Links = links
	
	// åˆå¹¶æ ‡ç­¾
	tagMap := make(map[string]bool)
	for _, tag := range existing.Tags {
		tagMap[tag] = true
	}
	for _, tag := range new.Tags {
		tagMap[tag] = true
	}
	
	tags := make([]string, 0, len(tagMap))
	for tag := range tagMap {
		tags = append(tags, tag)
	}
	merged.Tags = tags
	
	// ä½¿ç”¨æ›´æ–°çš„æ—¶é—´
	if new.Datetime.After(existing.Datetime) {
		merged.Datetime = new.Datetime
	}
	
	return merged
}

// hasOverlapResults æ£€æŸ¥æ˜¯å¦æœ‰é‡å ç»“æœ
func (m *AdvancedDataMerger) hasOverlapResults(existing, new *CacheOperation) bool {
	if len(existing.Data) == 0 || len(new.Data) == 0 {
		return false
	}
	
	// ç®€å•é‡å æ£€æµ‹ï¼šæ£€æŸ¥å‰å‡ ä¸ªç»“æœçš„æ ‡é¢˜
	checkCount := 3
	if len(existing.Data) < checkCount {
		checkCount = len(existing.Data)
	}
	if len(new.Data) < checkCount {
		checkCount = len(new.Data)
	}
	
	for i := 0; i < checkCount; i++ {
		for j := 0; j < checkCount; j++ {
			if existing.Data[i].Title == new.Data[j].Title {
				return true
			}
		}
	}
	
	return false
}

// chooseLongerTTL é€‰æ‹©æ›´é•¿çš„TTL
func (m *AdvancedDataMerger) chooseLongerTTL(ttl1, ttl2 time.Duration) time.Duration {
	if ttl1 > ttl2 {
		return ttl1
	}
	return ttl2
}

// chooseBetterPriority é€‰æ‹©æ›´å¥½çš„ä¼˜å…ˆçº§
func (m *AdvancedDataMerger) chooseBetterPriority(priority1, priority2 int) int {
	if priority1 < priority2 { // æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
		return priority1
	}
	return priority2
}

// updateMergeMetrics æ›´æ–°åˆå¹¶æŒ‡æ ‡
func (m *AdvancedDataMerger) updateMergeMetrics(mergeTime time.Duration) {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	m.mergeMetrics.TotalMergeTime += mergeTime
	
	// æ›´æ–°å¹³å‡æ—¶é—´
	if m.successfulMerges > 0 {
		m.mergeMetrics.AverageMergeTime = time.Duration(
			int64(m.mergeMetrics.TotalMergeTime) / m.successfulMerges)
	}
	
	// æ›´æ–°æœ€å¤§æ—¶é—´
	if mergeTime > m.mergeMetrics.MaxMergeTime {
		m.mergeMetrics.MaxMergeTime = mergeTime
	}
}

// updateMergeStatistics æ›´æ–°åˆå¹¶ç»Ÿè®¡
func (m *AdvancedDataMerger) updateMergeStatistics(existing, new, merged *CacheOperation) {
	m.mutex.Lock()
	defer m.mutex.Unlock()
	
	// æ•°æ®å¤§å°ç»Ÿè®¡
	beforeSize := int64(existing.DataSize + new.DataSize)
	afterSize := int64(merged.DataSize)
	
	m.mergeMetrics.DataSizeBefore += beforeSize
	m.mergeMetrics.DataSizeAfter += afterSize
	
	// è®¡ç®—å‹ç¼©æ¯”ä¾‹
	if m.mergeMetrics.DataSizeBefore > 0 {
		m.mergeMetrics.CompressionRatio = float64(m.mergeMetrics.DataSizeAfter) / 
		                                  float64(m.mergeMetrics.DataSizeBefore)
	}
	
	// æŒ‰ç±»å‹ç»Ÿè®¡
	m.mergeMetrics.MergesByPlugin[merged.PluginName]++
	m.mergeMetrics.MergesByKeyword[merged.Keyword]++
	
	// ç»“æœæ•´åˆç»Ÿè®¡
	originalCount := int64(len(existing.Data) + len(new.Data))
	mergedCount := int64(len(merged.Data))
	consolidated := originalCount - mergedCount
	
	if consolidated > 0 {
		m.mergeMetrics.ResultsConsolidated += consolidated
		m.mergeMetrics.StorageSaved += beforeSize - afterSize
	}
}

// GetMergeStats è·å–åˆå¹¶ç»Ÿè®¡
func (m *AdvancedDataMerger) GetMergeStats() map[string]interface{} {
	m.mutex.RLock()
	defer m.mutex.RUnlock()
	
	successRate := float64(0)
	if m.totalMerges > 0 {
		successRate = float64(m.successfulMerges) / float64(m.totalMerges)
	}
	
	return map[string]interface{}{
		"total_merges":         m.totalMerges,
		"successful_merges":    m.successfulMerges,
		"failed_merges":        m.failedMerges,
		"success_rate":         successRate,
		"merge_metrics":        m.mergeMetrics,
		"average_merge_time":   m.mergeMetrics.AverageMergeTime,
		"max_merge_time":       m.mergeMetrics.MaxMergeTime,
		"compression_ratio":    m.mergeMetrics.CompressionRatio,
		"duplicates_removed":   m.mergeMetrics.DuplicatesRemoved,
		"results_consolidated": m.mergeMetrics.ResultsConsolidated,
		"storage_saved":        m.mergeMetrics.StorageSaved,
	}
}

// å®ç°å„ç§åˆå¹¶ç­–ç•¥

// SameKeyMergeStrategy ç›¸åŒé”®åˆå¹¶ç­–ç•¥
type SameKeyMergeStrategy struct{}

func (s *SameKeyMergeStrategy) CanMerge(existing, new *CacheOperation) bool {
	return existing.Key == new.Key
}

func (s *SameKeyMergeStrategy) Merge(existing, new *CacheOperation) (*CacheOperation, error) {
	// å§”æ‰˜ç»™åˆå¹¶å™¨çš„æ–¹æ³•
	return nil, fmt.Errorf("åº”è¯¥ä½¿ç”¨åˆå¹¶å™¨çš„æ–¹æ³•")
}

func (s *SameKeyMergeStrategy) GetPriority() int {
	return 1
}

// SamePluginKeywordMergeStrategy åŒæ’ä»¶åŒå…³é”®è¯åˆå¹¶ç­–ç•¥
type SamePluginKeywordMergeStrategy struct{}

func (s *SamePluginKeywordMergeStrategy) CanMerge(existing, new *CacheOperation) bool {
	return existing.PluginName == new.PluginName && existing.Keyword == new.Keyword
}

func (s *SamePluginKeywordMergeStrategy) Merge(existing, new *CacheOperation) (*CacheOperation, error) {
	return nil, fmt.Errorf("åº”è¯¥ä½¿ç”¨åˆå¹¶å™¨çš„æ–¹æ³•")
}

func (s *SamePluginKeywordMergeStrategy) GetPriority() int {
	return 2
}

// DeduplicationMergeStrategy å»é‡åˆå¹¶ç­–ç•¥
type DeduplicationMergeStrategy struct{}

func (s *DeduplicationMergeStrategy) CanMerge(existing, new *CacheOperation) bool {
	// æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ç»“æœ
	return len(existing.Data) > 0 && len(new.Data) > 0
}

func (s *DeduplicationMergeStrategy) Merge(existing, new *CacheOperation) (*CacheOperation, error) {
	return nil, fmt.Errorf("åº”è¯¥ä½¿ç”¨åˆå¹¶å™¨çš„æ–¹æ³•")
}

func (s *DeduplicationMergeStrategy) GetPriority() int {
	return 4
}

// ContentSimilarityMergeStrategy å†…å®¹ç›¸ä¼¼æ€§åˆå¹¶ç­–ç•¥
type ContentSimilarityMergeStrategy struct{}

func (s *ContentSimilarityMergeStrategy) CanMerge(existing, new *CacheOperation) bool {
	// ç®€å•çš„ç›¸ä¼¼æ€§æ£€æµ‹ï¼šå…³é”®è¯ç›¸ä¼¼åº¦
	return existing.Keyword == new.Keyword || 
	       (len(existing.Keyword) > 3 && len(new.Keyword) > 3 && 
	        existing.Keyword[:3] == new.Keyword[:3])
}

func (s *ContentSimilarityMergeStrategy) Merge(existing, new *CacheOperation) (*CacheOperation, error) {
	return nil, fmt.Errorf("åº”è¯¥ä½¿ç”¨åˆå¹¶å™¨çš„æ–¹æ³•")
}

func (s *ContentSimilarityMergeStrategy) GetPriority() int {
	return 5
}