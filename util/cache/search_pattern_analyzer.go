package cache

import (
	"crypto/md5"
	"fmt"
	"regexp"
	"sort"
	"strings"
	"sync"
	"time"
)

// SearchPatternAnalyzer æœç´¢æ¨¡å¼åˆ†æå™¨
type SearchPatternAnalyzer struct {
	// æ¨¡å¼ç¼“å­˜
	patternCache     map[string]*SearchPattern
	cacheMutex       sync.RWMutex
	
	// åˆ†æè§„åˆ™
	keywordRules     []*KeywordRule
	
	// ç»Ÿè®¡ä¿¡æ¯
	analysisCount    int64
	cacheHitCount    int64
	
	// é…ç½®
	maxCacheSize     int
	cacheExpiry      time.Duration
}

// KeywordRule å…³é”®è¯è§„åˆ™
type KeywordRule struct {
	Name        string
	Pattern     *regexp.Regexp
	Priority    int
	Description string
}

// NewSearchPatternAnalyzer åˆ›å»ºæœç´¢æ¨¡å¼åˆ†æå™¨
func NewSearchPatternAnalyzer() *SearchPatternAnalyzer {
	analyzer := &SearchPatternAnalyzer{
		patternCache: make(map[string]*SearchPattern),
		maxCacheSize: 1000, // æœ€å¤§ç¼“å­˜1000ä¸ªæ¨¡å¼
		cacheExpiry:  1 * time.Hour, // 1å°æ—¶è¿‡æœŸ
	}
	
	// åˆå§‹åŒ–å…³é”®è¯è§„åˆ™
	analyzer.initializeKeywordRules()
	
	return analyzer
}

// initializeKeywordRules åˆå§‹åŒ–å…³é”®è¯è§„åˆ™
func (s *SearchPatternAnalyzer) initializeKeywordRules() {
	s.keywordRules = []*KeywordRule{
		{
			Name:        "ç”µå½±èµ„æº",
			Pattern:     regexp.MustCompile(`(?i)(ç”µå½±|movie|film|å½±ç‰‡|HD|4K|è“å…‰|BluRay)`),
			Priority:    1,
			Description: "ç”µå½±ç›¸å…³æœç´¢",
		},
		{
			Name:        "ç”µè§†å‰§èµ„æº", 
			Pattern:     regexp.MustCompile(`(?i)(ç”µè§†å‰§|TV|series|è¿ç»­å‰§|ç¾å‰§|éŸ©å‰§|æ—¥å‰§)`),
			Priority:    1,
			Description: "ç”µè§†å‰§ç›¸å…³æœç´¢",
		},
		{
			Name:        "åŠ¨æ¼«èµ„æº",
			Pattern:     regexp.MustCompile(`(?i)(åŠ¨æ¼«|anime|åŠ¨ç”»|æ¼«ç”»|manga)`),
			Priority:    1,
			Description: "åŠ¨æ¼«ç›¸å…³æœç´¢",
		},
		{
			Name:        "éŸ³ä¹èµ„æº",
			Pattern:     regexp.MustCompile(`(?i)(éŸ³ä¹|music|æ­Œæ›²|ä¸“è¾‘|album|MP3|FLAC)`),
			Priority:    2,
			Description: "éŸ³ä¹ç›¸å…³æœç´¢",
		},
		{
			Name:        "æ¸¸æˆèµ„æº",
			Pattern:     regexp.MustCompile(`(?i)(æ¸¸æˆ|game|å•æœº|ç½‘æ¸¸|æ‰‹æ¸¸|steam)`),
			Priority:    2,
			Description: "æ¸¸æˆç›¸å…³æœç´¢",
		},
		{
			Name:        "è½¯ä»¶èµ„æº",
			Pattern:     regexp.MustCompile(`(?i)(è½¯ä»¶|software|app|åº”ç”¨|å·¥å…·|ç ´è§£)`),
			Priority:    2,
			Description: "è½¯ä»¶ç›¸å…³æœç´¢",
		},
		{
			Name:        "å­¦ä¹ èµ„æº",
			Pattern:     regexp.MustCompile(`(?i)(æ•™ç¨‹|tutorial|è¯¾ç¨‹|å­¦ä¹ |æ•™å­¦|èµ„æ–™)`),
			Priority:    3,
			Description: "å­¦ä¹ èµ„æºæœç´¢",
		},
		{
			Name:        "æ–‡æ¡£èµ„æº",
			Pattern:     regexp.MustCompile(`(?i)(æ–‡æ¡£|doc|pdf|txt|ç”µå­ä¹¦|ebook)`),
			Priority:    3,
			Description: "æ–‡æ¡£èµ„æºæœç´¢",
		},
		{
			Name:        "é€šç”¨æœç´¢",
			Pattern:     regexp.MustCompile(`.*`), // åŒ¹é…æ‰€æœ‰
			Priority:    4,
			Description: "é€šç”¨æœç´¢æ¨¡å¼",
		},
	}
}

// AnalyzePattern åˆ†ææœç´¢æ¨¡å¼
func (s *SearchPatternAnalyzer) AnalyzePattern(op *CacheOperation) *SearchPattern {
	s.analysisCount++
	
	// ğŸ”§ ç”Ÿæˆç¼“å­˜é”®
	cacheKey := s.generateCacheKey(op)
	
	// ğŸš€ æ£€æŸ¥ç¼“å­˜
	s.cacheMutex.RLock()
	if cached, exists := s.patternCache[cacheKey]; exists {
		// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
		if time.Since(cached.LastAccessTime) < s.cacheExpiry {
			cached.LastAccessTime = time.Now()
			cached.Frequency++
			s.cacheMutex.RUnlock()
			s.cacheHitCount++
			return cached
		}
	}
	s.cacheMutex.RUnlock()
	
	// ğŸ¯ åˆ†ææ–°æ¨¡å¼
	pattern := s.analyzeNewPattern(op)
	
	// ğŸ—„ï¸ ç¼“å­˜ç»“æœ
	s.cachePattern(cacheKey, pattern)
	
	return pattern
}

// generateCacheKey ç”Ÿæˆç¼“å­˜é”®
func (s *SearchPatternAnalyzer) generateCacheKey(op *CacheOperation) string {
	// ä½¿ç”¨å…³é”®è¯å’Œæ’ä»¶åç”Ÿæˆç¼“å­˜é”®
	source := fmt.Sprintf("%s_%s", 
		s.normalizeKeyword(op.Keyword), 
		op.PluginName)
	
	// MD5å“ˆå¸Œä»¥èŠ‚çœå†…å­˜
	hash := md5.Sum([]byte(source))
	return fmt.Sprintf("%x", hash)
}

// normalizeKeyword æ ‡å‡†åŒ–å…³é”®è¯
func (s *SearchPatternAnalyzer) normalizeKeyword(keyword string) string {
	// è½¬æ¢ä¸ºå°å†™
	normalized := strings.ToLower(keyword)
	
	// ç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¤šä½™ç©ºæ ¼
	normalized = regexp.MustCompile(`[^\w\s\u4e00-\u9fff]`).ReplaceAllString(normalized, " ")
	normalized = regexp.MustCompile(`\s+`).ReplaceAllString(normalized, " ")
	normalized = strings.TrimSpace(normalized)
	
	return normalized
}

// analyzeNewPattern åˆ†ææ–°æ¨¡å¼
func (s *SearchPatternAnalyzer) analyzeNewPattern(op *CacheOperation) *SearchPattern {
	pattern := &SearchPattern{
		KeywordPattern: s.classifyKeyword(op.Keyword),
		PluginSet:      []string{op.PluginName},
		TimeWindow:     s.determineTimeWindow(op),
		Frequency:      1,
		LastAccessTime: time.Now(),
		Metadata:       make(map[string]interface{}),
	}
	
	// ğŸ” å…³é”®è¯åˆ†æ
	s.analyzeKeywordCharacteristics(pattern, op.Keyword)
	
	// ğŸ” æ’ä»¶åˆ†æ
	s.analyzePluginCharacteristics(pattern, op.PluginName)
	
	// ğŸ” æ—¶é—´æ¨¡å¼åˆ†æ
	s.analyzeTimePattern(pattern, op.Timestamp)
	
	return pattern
}

// classifyKeyword åˆ†ç±»å…³é”®è¯
func (s *SearchPatternAnalyzer) classifyKeyword(keyword string) string {
	// æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥è§„åˆ™
	for _, rule := range s.keywordRules {
		if rule.Pattern.MatchString(keyword) {
			return rule.Name
		}
	}
	
	return "é€šç”¨æœç´¢"
}

// analyzeKeywordCharacteristics åˆ†æå…³é”®è¯ç‰¹å¾
func (s *SearchPatternAnalyzer) analyzeKeywordCharacteristics(pattern *SearchPattern, keyword string) {
	metadata := pattern.Metadata
	
	// åˆ†æå…³é”®è¯é•¿åº¦
	metadata["keyword_length"] = len(keyword)
	
	// åˆ†æå…³é”®è¯å¤æ‚åº¦ï¼ˆåŒ…å«çš„è¯æ•°ï¼‰
	words := strings.Fields(keyword)
	metadata["word_count"] = len(words)
	
	// åˆ†ææ˜¯å¦åŒ…å«ç‰¹æ®Šå­—ç¬¦
	hasSpecialChars := regexp.MustCompile(`[^\w\s\u4e00-\u9fff]`).MatchString(keyword)
	metadata["has_special_chars"] = hasSpecialChars
	
	// åˆ†ææ˜¯å¦åŒ…å«æ•°å­—
	hasNumbers := regexp.MustCompile(`\d`).MatchString(keyword)
	metadata["has_numbers"] = hasNumbers
	
	// åˆ†æè¯­è¨€ç±»å‹
	hasChinese := regexp.MustCompile(`[\u4e00-\u9fff]`).MatchString(keyword)
	hasEnglish := regexp.MustCompile(`[a-zA-Z]`).MatchString(keyword)
	
	if hasChinese && hasEnglish {
		metadata["language"] = "mixed"
	} else if hasChinese {
		metadata["language"] = "chinese"
	} else if hasEnglish {
		metadata["language"] = "english"
	} else {
		metadata["language"] = "other"
	}
	
	// é¢„æµ‹æœç´¢é¢‘ç‡ï¼ˆåŸºäºå…³é”®è¯ç‰¹å¾ï¼‰
	complexity := len(words)
	if hasSpecialChars {
		complexity++
	}
	if hasNumbers {
		complexity++
	}
	
	// å¤æ‚åº¦è¶Šä½ï¼Œæœç´¢é¢‘ç‡å¯èƒ½è¶Šé«˜
	predictedFrequency := "medium"
	if complexity <= 2 {
		predictedFrequency = "high"
	} else if complexity >= 5 {
		predictedFrequency = "low"
	}
	
	metadata["predicted_frequency"] = predictedFrequency
}

// analyzePluginCharacteristics åˆ†ææ’ä»¶ç‰¹å¾
func (s *SearchPatternAnalyzer) analyzePluginCharacteristics(pattern *SearchPattern, pluginName string) {
	metadata := pattern.Metadata
	
	// æ’ä»¶ç±»å‹åˆ†æï¼ˆåŸºäºåç§°æ¨æ–­ï¼‰
	pluginType := "general"
	if strings.Contains(strings.ToLower(pluginName), "4k") {
		pluginType = "high_quality"
	} else if strings.Contains(strings.ToLower(pluginName), "pan") {
		pluginType = "cloud_storage"
	} else if strings.Contains(strings.ToLower(pluginName), "search") {
		pluginType = "search_engine"
	}
	
	metadata["plugin_type"] = pluginType
	metadata["plugin_name"] = pluginName
}

// analyzeTimePattern åˆ†ææ—¶é—´æ¨¡å¼
func (s *SearchPatternAnalyzer) analyzeTimePattern(pattern *SearchPattern, timestamp time.Time) {
	metadata := pattern.Metadata
	
	// æ—¶é—´æ®µåˆ†æ
	hour := timestamp.Hour()
	var timePeriod string
	switch {
	case hour >= 6 && hour < 12:
		timePeriod = "morning"
	case hour >= 12 && hour < 18:
		timePeriod = "afternoon"
	case hour >= 18 && hour < 22:
		timePeriod = "evening"
	default:
		timePeriod = "night"
	}
	
	metadata["time_period"] = timePeriod
	
	// å·¥ä½œæ—¥/å‘¨æœ«åˆ†æ
	weekday := timestamp.Weekday()
	isWeekend := weekday == time.Saturday || weekday == time.Sunday
	metadata["is_weekend"] = isWeekend
	
	// é¢„æµ‹æœ€ä½³ç¼“å­˜æ—¶é—´ï¼ˆåŸºäºæ—¶é—´æ¨¡å¼ï¼‰
	if isWeekend || timePeriod == "evening" {
		pattern.TimeWindow = 30 * time.Minute // é«˜å³°æœŸï¼Œè¾ƒé•¿ç¼“å­˜
	} else {
		pattern.TimeWindow = 15 * time.Minute // éé«˜å³°æœŸï¼Œè¾ƒçŸ­ç¼“å­˜
	}
}

// determineTimeWindow ç¡®å®šæ—¶é—´çª—å£
func (s *SearchPatternAnalyzer) determineTimeWindow(op *CacheOperation) time.Duration {
	// åŸºæœ¬æ—¶é—´çª—å£ï¼š15åˆ†é’Ÿ
	baseWindow := 15 * time.Minute
	
	// æ ¹æ®ä¼˜å…ˆçº§è°ƒæ•´
	switch op.Priority {
	case 1: // é«˜ä¼˜å…ˆçº§æ’ä»¶
		return baseWindow * 2 // 30åˆ†é’Ÿ
	case 2: // ä¸­é«˜ä¼˜å…ˆçº§æ’ä»¶
		return baseWindow * 3 / 2 // 22.5åˆ†é’Ÿ
	case 3: // ä¸­ç­‰ä¼˜å…ˆçº§æ’ä»¶
		return baseWindow // 15åˆ†é’Ÿ
	case 4: // ä½ä¼˜å…ˆçº§æ’ä»¶
		return baseWindow / 2 // 7.5åˆ†é’Ÿ
	default:
		return baseWindow
	}
}

// cachePattern ç¼“å­˜æ¨¡å¼
func (s *SearchPatternAnalyzer) cachePattern(cacheKey string, pattern *SearchPattern) {
	s.cacheMutex.Lock()
	defer s.cacheMutex.Unlock()
	
	// æ£€æŸ¥ç¼“å­˜å¤§å°ï¼Œå¿…è¦æ—¶æ¸…ç†
	if len(s.patternCache) >= s.maxCacheSize {
		s.cleanupCache()
	}
	
	s.patternCache[cacheKey] = pattern
}

// cleanupCache æ¸…ç†ç¼“å­˜
func (s *SearchPatternAnalyzer) cleanupCache() {
	now := time.Now()
	
	// æ”¶é›†éœ€è¦åˆ é™¤çš„é”®
	toDelete := make([]string, 0)
	for key, pattern := range s.patternCache {
		if now.Sub(pattern.LastAccessTime) > s.cacheExpiry {
			toDelete = append(toDelete, key)
		}
	}
	
	// å¦‚æœè¿‡æœŸåˆ é™¤ä¸å¤Ÿï¼ŒæŒ‰ä½¿ç”¨é¢‘ç‡åˆ é™¤
	if len(toDelete) < len(s.patternCache)/4 { // åˆ é™¤ä¸åˆ°25%
		// æŒ‰é¢‘ç‡æ’åºï¼Œåˆ é™¤ä½¿ç”¨é¢‘ç‡æœ€ä½çš„
		type patternFreq struct {
			key       string
			frequency int
			lastAccess time.Time
		}
		
		patterns := make([]patternFreq, 0, len(s.patternCache))
		for key, pattern := range s.patternCache {
			patterns = append(patterns, patternFreq{
				key:       key,
				frequency: pattern.Frequency,
				lastAccess: pattern.LastAccessTime,
			})
		}
		
		// æŒ‰é¢‘ç‡æ’åºï¼ˆé¢‘ç‡ä½çš„åœ¨å‰ï¼‰
		sort.Slice(patterns, func(i, j int) bool {
			if patterns[i].frequency == patterns[j].frequency {
				return patterns[i].lastAccess.Before(patterns[j].lastAccess)
			}
			return patterns[i].frequency < patterns[j].frequency
		})
		
		// åˆ é™¤å‰25%
		deleteCount := len(patterns) / 4
		for i := 0; i < deleteCount; i++ {
			toDelete = append(toDelete, patterns[i].key)
		}
	}
	
	// æ‰§è¡Œåˆ é™¤
	for _, key := range toDelete {
		delete(s.patternCache, key)
	}
}

// GetCacheStats è·å–ç¼“å­˜ç»Ÿè®¡
func (s *SearchPatternAnalyzer) GetCacheStats() map[string]interface{} {
	s.cacheMutex.RLock()
	defer s.cacheMutex.RUnlock()
	
	hitRate := float64(0)
	if s.analysisCount > 0 {
		hitRate = float64(s.cacheHitCount) / float64(s.analysisCount)
	}
	
	return map[string]interface{}{
		"cache_size":      len(s.patternCache),
		"max_cache_size":  s.maxCacheSize,
		"analysis_count":  s.analysisCount,
		"cache_hit_count": s.cacheHitCount,
		"hit_rate":        hitRate,
		"cache_expiry":    s.cacheExpiry,
	}
}

// GetPopularPatterns è·å–çƒ­é—¨æ¨¡å¼
func (s *SearchPatternAnalyzer) GetPopularPatterns(limit int) []*SearchPattern {
	s.cacheMutex.RLock()
	defer s.cacheMutex.RUnlock()
	
	patterns := make([]*SearchPattern, 0, len(s.patternCache))
	for _, pattern := range s.patternCache {
		patterns = append(patterns, pattern)
	}
	
	// æŒ‰é¢‘ç‡æ’åº
	sort.Slice(patterns, func(i, j int) bool {
		return patterns[i].Frequency > patterns[j].Frequency
	})
	
	if limit > 0 && limit < len(patterns) {
		patterns = patterns[:limit]
	}
	
	return patterns
}