package cache

import (
	"hash/fnv"
	"runtime"
	"sync"
	"sync/atomic"
	"time"
)

// å…¨å±€æ¸…ç†ä»»åŠ¡ç›¸å…³å˜é‡ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
var (
	globalCleanupTicker *time.Ticker
	globalCleanupOnce   sync.Once
	registeredCaches    []cleanupTarget
	cacheRegistryMutex  sync.RWMutex
)

// æ¸…ç†ç›®æ ‡æ¥å£
type cleanupTarget interface {
	CleanExpired()
}

// åˆ†ç‰‡å†…å­˜ç¼“å­˜é¡¹
type shardedMemoryCacheItem struct {
	data         []byte
	expiry       time.Time
	lastUsed     int64 // ä½¿ç”¨åŸå­æ“ä½œçš„æ—¶é—´æˆ³
	lastModified time.Time
	size         int
}

// å•ä¸ªåˆ†ç‰‡
type memoryCacheShard struct {
	items    map[string]*shardedMemoryCacheItem
	mutex    sync.RWMutex
	currSize int64
}

// åˆ†ç‰‡å†…å­˜ç¼“å­˜
type ShardedMemoryCache struct {
	shards    []*memoryCacheShard
	shardMask uint32 // ç”¨äºå¿«é€Ÿå–æ¨¡çš„æ©ç 
	maxItems  int
	maxSize   int64
	itemsPerShard int
	sizePerShard  int64
	diskCache     *ShardedDiskCache // ç£ç›˜ç¼“å­˜å¼•ç”¨
	diskCacheMutex sync.RWMutex     // ç£ç›˜ç¼“å­˜å¼•ç”¨çš„ä¿æŠ¤é”
}

// åˆ›å»ºæ–°çš„åˆ†ç‰‡å†…å­˜ç¼“å­˜
func NewShardedMemoryCache(maxItems int, maxSizeMB int) *ShardedMemoryCache {
	// åŠ¨æ€ç¡®å®šåˆ†ç‰‡æ•°é‡ï¼šåŸºäºCPUæ ¸å¿ƒæ•°ï¼Œä½†è‡³å°‘4ä¸ªï¼Œæœ€å¤š64ä¸ª
	shardCount := runtime.NumCPU() * 2
	if shardCount < 4 {
		shardCount = 4
	}
	if shardCount > 64 {
		shardCount = 64
	}
	
	// ç¡®ä¿åˆ†ç‰‡æ•°æ˜¯2çš„å¹‚ï¼Œä¾¿äºä½¿ç”¨æ©ç è¿›è¡Œå¿«é€Ÿå–æ¨¡
	shardCount = nextPowerOfTwo(shardCount)
	
	totalSize := int64(maxSizeMB) * 1024 * 1024
	itemsPerShard := maxItems / shardCount
	sizePerShard := totalSize / int64(shardCount)
	
	shards := make([]*memoryCacheShard, shardCount)
	for i := 0; i < shardCount; i++ {
		shards[i] = &memoryCacheShard{
			items: make(map[string]*shardedMemoryCacheItem),
		}
	}
	
	return &ShardedMemoryCache{
		shards:        shards,
		shardMask:     uint32(shardCount - 1), // ç”¨äºå¿«é€Ÿå–æ¨¡
		maxItems:      maxItems,
		maxSize:       totalSize,
		itemsPerShard: itemsPerShard,
		sizePerShard:  sizePerShard,
	}
}

// è·å–ä¸‹ä¸€ä¸ª2çš„å¹‚
func nextPowerOfTwo(n int) int {
	if n <= 1 {
		return 1
	}
	n--
	n |= n >> 1
	n |= n >> 2
	n |= n >> 4
	n |= n >> 8
	n |= n >> 16
	return n + 1
}

// è·å–åˆ†ç‰‡
func (c *ShardedMemoryCache) getShard(key string) *memoryCacheShard {
	h := fnv.New32a()
	h.Write([]byte(key))
	shardIndex := h.Sum32() & c.shardMask // ä½¿ç”¨æ©ç è¿›è¡Œå¿«é€Ÿå–æ¨¡
	return c.shards[shardIndex]
}

// è®¾ç½®ç¼“å­˜
func (c *ShardedMemoryCache) Set(key string, data []byte, ttl time.Duration) {
	c.SetWithTimestamp(key, data, ttl, time.Now())
}

// SetWithTimestamp è®¾ç½®ç¼“å­˜ï¼Œå¹¶æŒ‡å®šæœ€åä¿®æ”¹æ—¶é—´
func (c *ShardedMemoryCache) SetWithTimestamp(key string, data []byte, ttl time.Duration, lastModified time.Time) {
	shard := c.getShard(key)
	shard.mutex.Lock()
	defer shard.mutex.Unlock()
	
	// å¦‚æœå·²å­˜åœ¨ï¼Œå…ˆå‡å»æ—§é¡¹çš„å¤§å°
	if item, exists := shard.items[key]; exists {
		atomic.AddInt64(&shard.currSize, -int64(item.size))
	}
	
	// åˆ›å»ºæ–°çš„ç¼“å­˜é¡¹
	now := time.Now()
	item := &shardedMemoryCacheItem{
		data:         data,
		expiry:       now.Add(ttl),
		lastUsed:     now.UnixNano(),
		lastModified: lastModified,
		size:         len(data),
	}
	
	// æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç©ºé—´
	if len(shard.items) >= c.itemsPerShard || shard.currSize+int64(len(data)) > c.sizePerShard {
		c.evictFromShard(shard)
	}
	
	// å­˜å‚¨æ–°é¡¹
	shard.items[key] = item
	atomic.AddInt64(&shard.currSize, int64(len(data)))
}

// è·å–ç¼“å­˜
func (c *ShardedMemoryCache) Get(key string) ([]byte, bool) {
	shard := c.getShard(key)
	shard.mutex.RLock()
	item, exists := shard.items[key]
	shard.mutex.RUnlock()
	
	if !exists {
		return nil, false
	}
	
	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(item.expiry) {
		shard.mutex.Lock()
		delete(shard.items, key)
		atomic.AddInt64(&shard.currSize, -int64(item.size))
		shard.mutex.Unlock()
		return nil, false
	}
	
	// åŸå­æ“ä½œæ›´æ–°æœ€åä½¿ç”¨æ—¶é—´ï¼Œé¿å…é¢å¤–çš„é”
	atomic.StoreInt64(&item.lastUsed, time.Now().UnixNano())
	
	return item.data, true
}

// GetWithTimestamp è·å–ç¼“å­˜åŠå…¶æœ€åä¿®æ”¹æ—¶é—´
func (c *ShardedMemoryCache) GetWithTimestamp(key string) ([]byte, time.Time, bool) {
	shard := c.getShard(key)
	shard.mutex.RLock()
	item, exists := shard.items[key]
	shard.mutex.RUnlock()
	
	if !exists {
		return nil, time.Time{}, false
	}
	
	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(item.expiry) {
		shard.mutex.Lock()
		delete(shard.items, key)
		atomic.AddInt64(&shard.currSize, -int64(item.size))
		shard.mutex.Unlock()
		return nil, time.Time{}, false
	}
	
	// åŸå­æ“ä½œæ›´æ–°æœ€åä½¿ç”¨æ—¶é—´
	atomic.StoreInt64(&item.lastUsed, time.Now().UnixNano())
	
	return item.data, item.lastModified, true
}

// GetLastModified è·å–ç¼“å­˜é¡¹çš„æœ€åä¿®æ”¹æ—¶é—´
func (c *ShardedMemoryCache) GetLastModified(key string) (time.Time, bool) {
	shard := c.getShard(key)
	shard.mutex.RLock()
	defer shard.mutex.RUnlock()
	
	item, exists := shard.items[key]
	if !exists {
		return time.Time{}, false
	}
	
	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(item.expiry) {
		return time.Time{}, false
	}
	
	return item.lastModified, true
}

// ä»æŒ‡å®šåˆ†ç‰‡ä¸­é©±é€æœ€ä¹…æœªä½¿ç”¨çš„é¡¹ï¼ˆå¸¦ç£ç›˜å¤‡ä»½ï¼‰
func (c *ShardedMemoryCache) evictFromShard(shard *memoryCacheShard) {
	var oldestKey string
	var oldestItem *shardedMemoryCacheItem
	var oldestTime int64 = 9223372036854775807 // int64æœ€å¤§å€¼
	
	for k, v := range shard.items {
		lastUsed := atomic.LoadInt64(&v.lastUsed)
		if lastUsed < oldestTime {
			oldestKey = k
			oldestItem = v
			oldestTime = lastUsed
		}
	}
	
	// å¦‚æœæ‰¾åˆ°äº†æœ€ä¹…æœªä½¿ç”¨çš„é¡¹ï¼Œåˆ é™¤å®ƒ
	if oldestKey != "" && oldestItem != nil {
		// ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šæ·˜æ±°å‰æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·ç›˜ä¿æŠ¤
		diskCache := c.getDiskCacheReference()
		if time.Now().Before(oldestItem.expiry) && diskCache != nil {
			// æ•°æ®è¿˜æ²¡è¿‡æœŸï¼Œå¼‚æ­¥åˆ·æ–°åˆ°ç£ç›˜ä¿å­˜
			go func(key string, data []byte, expiry time.Time) {
				ttl := time.Until(expiry)
				if ttl > 0 {
					diskCache.Set(key, data, ttl) // ä¿æŒç›¸åŒTTL
				}
			}(oldestKey, oldestItem.data, oldestItem.expiry)
		}
		
		// ä»å†…å­˜ä¸­åˆ é™¤
		atomic.AddInt64(&shard.currSize, -int64(oldestItem.size))
		delete(shard.items, oldestKey)
	}
}

// æ¸…ç†è¿‡æœŸé¡¹
func (c *ShardedMemoryCache) CleanExpired() {
	now := time.Now()
	
	// å¹¶è¡Œæ¸…ç†æ‰€æœ‰åˆ†ç‰‡
	var wg sync.WaitGroup
	for _, shard := range c.shards {
		wg.Add(1)
		go func(s *memoryCacheShard) {
			defer wg.Done()
			s.mutex.Lock()
			defer s.mutex.Unlock()
			
			for k, v := range s.items {
				if now.After(v.expiry) {
					atomic.AddInt64(&s.currSize, -int64(v.size))
					delete(s.items, k)
				}
			}
		}(shard)
	}
	wg.Wait()
}

// Delete åˆ é™¤æŒ‡å®šé”®çš„ç¼“å­˜é¡¹
func (c *ShardedMemoryCache) Delete(key string) {
	shard := c.getShard(key)
	shard.mutex.Lock()
	defer shard.mutex.Unlock()
	
	if item, exists := shard.items[key]; exists {
		atomic.AddInt64(&shard.currSize, -int64(item.size))
		delete(shard.items, key)
	}
}

// Clear æ¸…ç©ºæ‰€æœ‰ç¼“å­˜é¡¹
func (c *ShardedMemoryCache) Clear() {
	// å¹¶è¡Œæ¸…ç†æ‰€æœ‰åˆ†ç‰‡
	var wg sync.WaitGroup
	for _, shard := range c.shards {
		wg.Add(1)
		go func(s *memoryCacheShard) {
			defer wg.Done()
			s.mutex.Lock()
			defer s.mutex.Unlock()
			
			s.items = make(map[string]*shardedMemoryCacheItem)
			atomic.StoreInt64(&s.currSize, 0)
		}(shard)
	}
	wg.Wait()
}

// å¯åŠ¨å…¨å±€æ¸…ç†ä»»åŠ¡ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
func startGlobalCleanupTask() {
	globalCleanupOnce.Do(func() {
		globalCleanupTicker = time.NewTicker(5 * time.Minute)
		go func() {
			for range globalCleanupTicker.C {
				cacheRegistryMutex.RLock()
				caches := make([]cleanupTarget, len(registeredCaches))
				copy(caches, registeredCaches)
				cacheRegistryMutex.RUnlock()
				
				// å¹¶è¡Œæ¸…ç†æ‰€æœ‰æ³¨å†Œçš„ç¼“å­˜
				for _, cache := range caches {
					go cache.CleanExpired()
				}
			}
		}()
	})
}

// æ³¨å†Œç¼“å­˜åˆ°å…¨å±€æ¸…ç†ä»»åŠ¡
func registerForCleanup(cache cleanupTarget) {
	cacheRegistryMutex.Lock()
	defer cacheRegistryMutex.Unlock()
	registeredCaches = append(registeredCaches, cache)
}

// å¯åŠ¨å®šæœŸæ¸…ç†ï¼ˆä¿®æ”¹ä¸ºä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼‰
func (c *ShardedMemoryCache) StartCleanupTask() {
	registerForCleanup(c)
	startGlobalCleanupTask()
}

// SetDiskCacheReference è®¾ç½®ç£ç›˜ç¼“å­˜å¼•ç”¨
func (c *ShardedMemoryCache) SetDiskCacheReference(diskCache *ShardedDiskCache) {
	c.diskCacheMutex.Lock()
	defer c.diskCacheMutex.Unlock()
	c.diskCache = diskCache
}

// getDiskCacheReference è·å–ç£ç›˜ç¼“å­˜å¼•ç”¨
func (c *ShardedMemoryCache) getDiskCacheReference() *ShardedDiskCache {
	c.diskCacheMutex.RLock()
	defer c.diskCacheMutex.RUnlock()
	return c.diskCache
}

// MemoryCacheItem å†…å­˜ç¼“å­˜é¡¹ç»“æ„ï¼ˆç”¨äºå¯¼å‡ºï¼‰
type MemoryCacheItem struct {
	Data []byte
	TTL  time.Duration
}

// GetAllItems è·å–å†…å­˜ç¼“å­˜ä¸­çš„æ‰€æœ‰é¡¹
func (c *ShardedMemoryCache) GetAllItems() map[string]*MemoryCacheItem {
	result := make(map[string]*MemoryCacheItem)
	now := time.Now()
	
	// éå†æ‰€æœ‰åˆ†ç‰‡
	for _, shard := range c.shards {
		shard.mutex.RLock()
		for key, item := range shard.items {
			// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
			if !item.expiry.IsZero() && now.After(item.expiry) {
				continue // è·³è¿‡è¿‡æœŸé¡¹
			}
			
			// è®¡ç®—å‰©ä½™TTL
			var ttl time.Duration
			if !item.expiry.IsZero() {
				ttl = item.expiry.Sub(now)
				if ttl <= 0 {
					continue // è·³è¿‡å³å°†è¿‡æœŸçš„é¡¹
				}
			}
			
			result[key] = &MemoryCacheItem{
				Data: item.data,
				TTL:  ttl,
			}
		}
		shard.mutex.RUnlock()
	}
	
	return result
}